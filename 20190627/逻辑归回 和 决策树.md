# 逻辑归回
和
决策树

## 逻辑回归

### 对数据整体结构的分析优于决策树

### 擅长分析线性关系

### 对极值比较敏感，容易受极端值的影响

### 算法优缺点

- 优点

	- 始终着眼整个数据的拟合，所以对全局把握较好

- 缺点

	- 但无法兼顾局部数据，或者说缺乏探查局部结构的内在机制

### 应用

- 原则上可以提供数据中每个观察点的概率，而决策树只能把挖掘对象分为有限的概率组群
- 要求一定的训练和技巧

## 决策树

### 对局部结构的分析优于逻辑回归

### 对线性关系的把握较差

### 算法优缺点

- 优点

	- 采用分割的方法，所以能够深入数据细部，但同时失去了对全局的把握

- 缺点

	- 一个分层一旦形成，它和别的层面或节点的关系就被切断了，以后的挖掘只能在局部中进行
	- 同时由于切分，样本数量不断萎缩，所以无法支持对多变量的同时检验

### 应用

- 决策树的结果和逻辑回归相比略显粗糙
- 决策树比较容易上手，需要的数据预处理较少

## 取长补短

### 主要思路

- 利用决策树对局部数据结构优越的把握能力增加逻辑回归的效力。

### 做法

- 一种是从决策树分析中找出数据局部结构，作为在逻辑回归中构建依变量（interaction)的依据
- 另一种是在需要对预测因子进行离散化处理时，利用决策树分析决定最佳切分点。还有一种是把决策树分类的最终结果作为预测变量，和其他协变量一起代入回归模型，又称为“嫁接式模型”。
